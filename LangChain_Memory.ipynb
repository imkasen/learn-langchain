{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNqvTHBxtKlgYFqM1O2MbGd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Memory Management"],"metadata":{"id":"VWbecyOO6ruY"}},{"cell_type":"markdown","source":["聊天机器人的一个主要特点是能使用以前的对话内容作为上下文。这种状态管理有多种形式，包括：\n","\n","- 简单地将以前的信息塞进聊天模型提示中。\n","- 如上，但会修剪旧信息，以减少模型需要处理的干扰信息量。\n","- 更复杂的修改，如为长对话合成摘要。"],"metadata":{"id":"tdmz2iAx6uTW"}},{"cell_type":"markdown","source":["## Introduction"],"metadata":{"id":"BxiG5QkoOfxY"}},{"cell_type":"markdown","source":["一个记忆系统需要支持两个基本动作：读取和写入。回想一下，每个链定义了一些核心执行逻辑，期望特定的输入。这些输入中的一部分直接来自用户，但有些输入则可以来自于记忆。在一次给定的运行中，一个链将与它的记忆系统互动两次。\n","\n","- 在接收初步用户输入但在执行核心逻辑之前，链会从其记忆系统读取并增强用户输入。\n","- 在执行核心逻辑之后但在返回答案之前，链将会将当前运行的输入和输出写入记忆中，以便在未来的运行中可以参照。"],"metadata":{"id":"th41DCozOhIa"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"H7U_YCke6-yS"}},{"cell_type":"code","source":["%pip install --upgrade --quiet langchain langchain-google-genai"],"metadata":{"id":"LBnpckJQ7Ac8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","API_KEY = userdata.get('API_KEY')"],"metadata":{"id":"iW9wgDKm8x-1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","chat = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", google_api_key=API_KEY)"],"metadata":{"id":"6lEpgKmw8vbU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Message Passing"],"metadata":{"id":"3Fd4-p7T9Pwr"}},{"cell_type":"markdown","source":["最简单的记忆形式就是将聊天记录信息传递到一个链中。下面是一个例子："],"metadata":{"id":"45Yvz6Fm9TBU"}},{"cell_type":"code","source":["from langchain_core.messages import AIMessage, HumanMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","    ]\n",")\n","\n","chain = prompt | chat\n","\n","response = chain.invoke(\n","    {\n","        \"messages\": [\n","            HumanMessage(\n","                content=\"Translate this sentence from English to French: I love programming.\"\n","            ),\n","            AIMessage(content=\"J'adore la programmation.\"),\n","            HumanMessage(content=\"What did you just say?\"),\n","        ],\n","    }\n",")\n","response"],"metadata":{"id":"z9zIdW3Y9V1p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715233872977,"user_tz":-480,"elapsed":2047,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"50cb29b3-65dd-4572-eb71-c8541eae48ef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='I said \"J\\'adore la programmation\" which is the French translation for \"I love programming\". \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-88045024-8232-4b31-905a-35fe7f321bbe-0')"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["我们可以看到，通过将之前的对话传递到链中，聊天机器人可以将其作为回答问题的上下文。这就是聊天机器人记忆的基本概念。"],"metadata":{"id":"2GOjHR7x_Dat"}},{"cell_type":"markdown","source":["## Chat Message History"],"metadata":{"id":"Fha2sWzE_ElT"}},{"cell_type":"markdown","source":["直接以数组形式存储和传递消息完全没问题，但我们也可以使用 LangChain 内置的消息历史记录类来存储和加载消息。"],"metadata":{"id":"Ph1MRAp-_FyV"}},{"cell_type":"code","source":["from langchain.memory import ChatMessageHistory\n","\n","demo_ephemeral_chat_history = ChatMessageHistory()\n","demo_ephemeral_chat_history.add_user_message(\n","    \"Translate this sentence from English to French: I love programming.\"\n",")\n","demo_ephemeral_chat_history.add_ai_message(\"J'adore la programmation.\")\n","\n","demo_ephemeral_chat_history"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scEvMBR0_rbY","executionInfo":{"status":"ok","timestamp":1715233878338,"user_tz":-480,"elapsed":356,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"f4d2b097-2494-4d1a-a2a3-f55701ae390d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["InMemoryChatMessageHistory(messages=[HumanMessage(content='Translate this sentence from English to French: I love programming.'), AIMessage(content=\"J'adore la programmation.\")])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["demo_ephemeral_chat_history.messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3BEtkEc_w5t","executionInfo":{"status":"ok","timestamp":1715233880742,"user_tz":-480,"elapsed":334,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"9833bf49-526c-409a-b164-e3fdf3b32a17"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='Translate this sentence from English to French: I love programming.'),\n"," AIMessage(content=\"J'adore la programmation.\")]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["我们可以直接用它来为我们的链存储多轮对话："],"metadata":{"id":"SE22FNm__8HP"}},{"cell_type":"code","source":["demo_ephemeral_chat_history = ChatMessageHistory()\n","\n","input1 = \"Translate this sentence from English to French: I love programming.\"\n","demo_ephemeral_chat_history.add_user_message(input1)\n","\n","response = chain.invoke(\n","    {\n","        \"messages\": demo_ephemeral_chat_history.messages,\n","    }\n",")\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8Jhj6pJ_72G","executionInfo":{"status":"ok","timestamp":1715233883701,"user_tz":-480,"elapsed":1369,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"2f8461e3-72fa-422b-a665-9897f3b4cde8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"J'adore programmer. \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-5b427786-fbb8-47f8-9e4d-c6e6137c4df5-0')"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["print(response.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ik-BcBorAYnZ","executionInfo":{"status":"ok","timestamp":1715233911520,"user_tz":-480,"elapsed":319,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"541f497b-9a1f-44a6-eb71-ae6a700a11b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["J'adore programmer. \n","\n"]}]},{"cell_type":"code","source":["demo_ephemeral_chat_history.add_ai_message(response)\n","\n","input2 = \"What did I just ask you?\"\n","demo_ephemeral_chat_history.add_user_message(input2)\n","\n","response = chain.invoke(\n","    {\n","        \"messages\": demo_ephemeral_chat_history.messages,\n","    }\n",")\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQZ7-A_wAHQf","executionInfo":{"status":"ok","timestamp":1715233932251,"user_tz":-480,"elapsed":1515,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"1f8c01d9-e15a-4b15-a952-d77008ee34c3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='You asked me to translate the sentence \"I love programming\" from English to French. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-1d9afa50-1701-45b8-a23c-24217a20ed45-0')"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["print(response.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EwN6zhmaAfSM","executionInfo":{"status":"ok","timestamp":1715233935071,"user_tz":-480,"elapsed":335,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"9403ba79-c9d0-4e59-91f9-8861abe1e28e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["You asked me to translate the sentence \"I love programming\" from English to French. \n","\n"]}]},{"cell_type":"markdown","source":["## Memory Types"],"metadata":{"id":"73i9KPTNU6ep"}},{"cell_type":"markdown","source":["### Conversation Buffer"],"metadata":{"id":"pUiN0-MSU8Uv"}},{"cell_type":"markdown","source":["`ConversationBufferMemory` 是一种极其简单的记忆形式，它所做的就是把聊天消息保存在内存中，并将这些消息输入到提示模板。"],"metadata":{"id":"icGUOeOEWRV0"}},{"cell_type":"code","source":["from langchain.memory import ConversationBufferMemory\n","\n","memory = ConversationBufferMemory()\n","memory.chat_memory.add_user_message(\"hi!\")\n","memory.chat_memory.add_ai_message(\"what's up?\")\n","\n","memory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J5cP4GezP4-V","executionInfo":{"status":"ok","timestamp":1715233970849,"user_tz":-480,"elapsed":327,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"dcee27dd-c822-483b-dcae-3c8a56422d04"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='hi!'), AIMessage(content=\"what's up?\")]))"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["memory.chat_memory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_vpAyM3QC4l","executionInfo":{"status":"ok","timestamp":1715233973948,"user_tz":-480,"elapsed":327,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"a6d6ed41-e0ee-47c9-cfa9-16867b23a22f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["InMemoryChatMessageHistory(messages=[HumanMessage(content='hi!'), AIMessage(content=\"what's up?\")])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["memory.chat_memory.messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maQZS-7-QGa3","executionInfo":{"status":"ok","timestamp":1715233975876,"user_tz":-480,"elapsed":348,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"471c6a18-41b6-4254-8b23-18f54754a4c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='hi!'), AIMessage(content=\"what's up?\")]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["另一种使用方式："],"metadata":{"id":"zKCk1VLYEIVN"}},{"cell_type":"code","source":["from langchain.memory import ConversationBufferMemory\n","\n","memory = ConversationBufferMemory()\n","memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2FkVUIsUVDWE","executionInfo":{"status":"ok","timestamp":1715233998593,"user_tz":-480,"elapsed":336,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"477dd861-e62f-429a-8cc8-c9870fe2ca9d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: hi\\nAI: whats up'}"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["在这个示例中，你可以注意到 `load_memory_variables` 返回了一个名为 `history` 的键值。这意味着你的链（以及可能的输入提示词）可能会期望一个名为 `history` 的输入。一般而言，你可以通过在记忆类中设置参数来管理这个变量。例如，如果你希望记忆变量在 `chat_history` 关键字中返回，你可以这样做："],"metadata":{"id":"kDYb_0UTSgQe"}},{"cell_type":"code","source":["memory = ConversationBufferMemory(memory_key=\"chat_history\")\n","memory.chat_memory.add_user_message(\"hi!\")\n","memory.chat_memory.add_ai_message(\"what's up?\")\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k794GD1ySwpS","executionInfo":{"status":"ok","timestamp":1715233985854,"user_tz":-480,"elapsed":355,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"4d062491-9cb5-441b-8839-a5d85dd31745"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'chat_history': \"Human: hi!\\nAI: what's up?\"}"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["最常见的一种使用记忆的方式是返回聊天信息的列表。这些信息可以整合成一个字符串返回（当要传入 LLMs 时 这种方式很有用）或者作为一个聊天消息的列表返回（在传入 ChatModels 时这种方式很有用）。\n","\n","默认情况下，它们以一整串字符串的方式返回。为了以消息列表的形式返回，你可以设置 `return_messages=True`。"],"metadata":{"id":"QytWK1XeS59z"}},{"cell_type":"code","source":["memory = ConversationBufferMemory(return_messages=True)\n","\n","memory.chat_memory.add_user_message(\"hi!\")\n","memory.chat_memory.add_ai_message(\"what's up?\")\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5p_e7v_OTpzj","executionInfo":{"status":"ok","timestamp":1715233990292,"user_tz":-480,"elapsed":324,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"fa9114da-1a77-4a4b-a9dd-8d11193aecee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': [HumanMessage(content='hi!'), AIMessage(content=\"what's up?\")]}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["memory = ConversationBufferMemory(return_messages=True)\n","memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KMo781szVKIs","executionInfo":{"status":"ok","timestamp":1715234002851,"user_tz":-480,"elapsed":464,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"0a743dc8-728e-4f98-c077-a45266948d5d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': [HumanMessage(content='hi'), AIMessage(content='whats up')]}"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["在链中使用："],"metadata":{"id":"BqLAKV2mVamf"}},{"cell_type":"code","source":["from langchain_google_genai import GoogleGenerativeAI\n","from langchain.chains import ConversationChain\n","\n","llm = GoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", google_api_key=API_KEY)\n","conversation = ConversationChain(\n","    llm=llm,\n","    verbose=True,\n","    memory=ConversationBufferMemory()\n",")"],"metadata":{"id":"GNbZ3v51VX4N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi there!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"hzFA4o0vVvFQ","executionInfo":{"status":"ok","timestamp":1715234013720,"user_tz":-480,"elapsed":1394,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"3b0176e0-7674-473c-c09f-e1eb504de7f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi there!\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'Hello! 👋 How can I help you today? 😊 \\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["### Conversation Buffer Window"],"metadata":{"id":"8SPj0RWpV7fK"}},{"cell_type":"markdown","source":["`ConversationBufferWindowMemory` 跟踪并保存随时间发展的对话互动列表。它只保留最近的 K 次对话记录。这种做法有助于创建一个包含最新互动记录的滑动视窗，可以有效地避免缓存变得过大。"],"metadata":{"id":"hy0-jkZDV-K8"}},{"cell_type":"code","source":["from langchain.memory import ConversationBufferWindowMemory\n","\n","memory = ConversationBufferWindowMemory(k=1)\n","memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n","memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oooYw3hJWwyX","executionInfo":{"status":"ok","timestamp":1715234018004,"user_tz":-480,"elapsed":344,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"74f27a4f-b76d-4b9a-f1af-209264164c73"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: not much you\\nAI: not much'}"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["memory = ConversationBufferWindowMemory(k=1, return_messages=True)\n","memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n","memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuBRNC1rW4XB","executionInfo":{"status":"ok","timestamp":1715234020472,"user_tz":-480,"elapsed":2,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"9f546b08-b93b-413f-bf80-2b08218893b9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': [HumanMessage(content='not much you'),\n","  AIMessage(content='not much')]}"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["### Entity"],"metadata":{"id":"DbNbJuoBXjTl"}},{"cell_type":"markdown","source":["实体记忆在对话中记住了关于特定实体的既定事实。它提取关于实体的信息（使用一个 LLM）并且随着时间的推移建立起关于该实体的知识（也使用一个 LLM）。"],"metadata":{"id":"ims-7FIyXlvB"}},{"cell_type":"code","source":["from langchain.memory import ConversationEntityMemory\n","\n","memory = ConversationEntityMemory(llm=llm)\n","_input = {\"input\": \"Deven & Sam are working on a hackathon project\"}\n","memory.load_memory_variables(_input)\n","memory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_IompGh67Ts","executionInfo":{"status":"ok","timestamp":1715234214051,"user_tz":-480,"elapsed":1433,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"93a0acf3-f688-4816-849d-abc6ba9e1911"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConversationEntityMemory(llm=GoogleGenerativeAI(model='gemini-1.5-pro-latest', google_api_key=SecretStr('**********'), client=genai.GenerativeModel(\n","    model_name='models/gemini-1.5-pro-latest',\n","    generation_config={},\n","    safety_settings={},\n","    tools=None,\n","    system_instruction=None,\n",")), entity_cache=['Deven', 'Sam'])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["memory.save_context(\n","    _input,\n","    {\"output\": \" That sounds like a great project! What kind of project are they working on?\"}\n",")\n","memory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOzl7q6u7OmW","executionInfo":{"status":"ok","timestamp":1715234260553,"user_tz":-480,"elapsed":2921,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"ee2cfa50-0d6e-46d8-ba2e-dfbfe3d72e2f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConversationEntityMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Deven & Sam are working on a hackathon project'), AIMessage(content=' That sounds like a great project! What kind of project are they working on?')]), llm=GoogleGenerativeAI(model='gemini-1.5-pro-latest', google_api_key=SecretStr('**********'), client=genai.GenerativeModel(\n","    model_name='models/gemini-1.5-pro-latest',\n","    generation_config={},\n","    safety_settings={},\n","    tools=None,\n","    system_instruction=None,\n",")), entity_cache=['Deven', 'Sam'], entity_store=InMemoryEntityStore(store={'Deven': 'Updated summary: Deven is working on a hackathon project with Sam.', 'Sam': 'Updated summary: Sam is working on a hackathon project with Deven.'}))"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["memory.load_memory_variables({\"input\": 'who is Sam'})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0xiaRaVE7nsZ","executionInfo":{"status":"ok","timestamp":1715234322790,"user_tz":-480,"elapsed":1682,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"9eb053f2-a53d-4df8-c970-cbaa864c05ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: Deven & Sam are working on a hackathon project\\nAI:  That sounds like a great project! What kind of project are they working on?',\n"," 'entities': {'Sam': 'Updated summary: Sam is working on a hackathon project with Deven.'}}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["memory = ConversationEntityMemory(llm=llm, return_messages=True)\n","\n","_input = {\"input\": \"Deven & Sam are working on a hackathon project\"}\n","memory.load_memory_variables(_input)\n","memory.save_context(\n","    _input,\n","    {\"output\": \" That sounds like a great project! What kind of project are they working on?\"}\n",")\n","memory.load_memory_variables({\"input\": 'who is Sam'})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdkHH02i7v-f","executionInfo":{"status":"ok","timestamp":1715234475574,"user_tz":-480,"elapsed":11866,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"87950d81-5f10-4f81-99e8-56b3d8f45e2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_core.language_models.llms:Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"]},{"output_type":"execute_result","data":{"text/plain":["{'history': [HumanMessage(content='Deven & Sam are working on a hackathon project'),\n","  AIMessage(content=' That sounds like a great project! What kind of project are they working on?')],\n"," 'entities': {'Sam': 'Updated summary:\\nSam is working on a hackathon project with Deven.'}}"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["### Conversation Knowledge Graph"],"metadata":{"id":"X2mmLtHD8dUW"}},{"cell_type":"markdown","source":["这种类型的记忆使用知识图谱来重建记忆。"],"metadata":{"id":"_yKeurW88utz"}},{"cell_type":"code","source":["from langchain.memory import ConversationKGMemory\n","\n","memory = ConversationKGMemory(llm=llm)\n","memory.save_context({\"input\": \"say hi to sam\"}, {\"output\": \"who is sam\"})\n","memory.save_context({\"input\": \"sam is a friend\"}, {\"output\": \"okay\"})\n","\n","memory.load_memory_variables({\"input\": \"who is sam\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"foFSlYnx80Yn","executionInfo":{"status":"ok","timestamp":1715234673970,"user_tz":-480,"elapsed":5180,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"b81d18b0-b8a3-4774-fa98-86473b6d8879"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'On Sam: Sam is a friend.'}"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["memory = ConversationKGMemory(llm=llm, return_messages=True)\n","memory.save_context({\"input\": \"say hi to sam\"}, {\"output\": \"who is sam\"})\n","memory.save_context({\"input\": \"sam is a friend\"}, {\"output\": \"okay\"})\n","\n","memory.load_memory_variables({\"input\": \"who is sam\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Km8R8J929DQK","executionInfo":{"status":"ok","timestamp":1715234781823,"user_tz":-480,"elapsed":333,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"c855ec3c-cecc-4d35-c6cf-006d2cf7e44c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': [SystemMessage(content='On Sam: Sam is a friend.')]}"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["我们也可以更加模块化地从一条新消息中获取当前实体（将使用之前的消息作为上下文）。"],"metadata":{"id":"PZIwfU_u9kwk"}},{"cell_type":"code","source":["memory.get_current_entities(\"what's Sams favorite color?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0W7_s5gq9lHs","executionInfo":{"status":"ok","timestamp":1715234834723,"user_tz":-480,"elapsed":1935,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"34679187-dc04-4279-fd44-73dfd5a88e53"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Sams']"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["我们也可以更加模块化地从一条新消息中获取知识三元组（将使用之前的消息作为上下文）。"],"metadata":{"id":"rWK6JZCB9yjR"}},{"cell_type":"code","source":["memory.get_knowledge_triplets(\"her favorite color is red\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEmWr1un9y4k","executionInfo":{"status":"ok","timestamp":1715234884028,"user_tz":-480,"elapsed":2087,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"a063c26d-141a-43ea-fd08-09b83de0d1b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[KnowledgeTriple(subject='her', predicate='favorite color', object_='red')]"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["### Conversation Summary"],"metadata":{"id":"7sOEg_ca-oXl"}},{"cell_type":"markdown","source":["现在让我们来看一个略微复杂的记忆类型 `ConversationSummaryMemory`。这种记忆类型会随着时间的推移创建对话的总结。这对于压缩对话中随时间积累的信息是有用的。会话总结记忆在对话发生时总结内容，并将当前的总结存储在记忆中。这个记忆之后可以用来将到目前为止的对话总结注入到一个提示词/链中。这种记忆对长时间的对话最有用，因为如果直接在提示词中保持之前的消息历史会占用太多的 Token。"],"metadata":{"id":"OtIXAibF-pGJ"}},{"cell_type":"code","source":["from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n","\n","memory = ConversationSummaryMemory(llm=llm)\n","memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gP3dofbF_CGl","executionInfo":{"status":"ok","timestamp":1715235230165,"user_tz":-480,"elapsed":1521,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"3c3da40c-3243-4197-e4da-9c1a6539b481"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'New summary:\\nThe human greets the AI and the AI responds with an informal greeting in return. \\n'}"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["memory = ConversationSummaryMemory(llm=llm, return_messages=True)\n","memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_c0wYQK3_ZEQ","executionInfo":{"status":"ok","timestamp":1715235309816,"user_tz":-480,"elapsed":1734,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"2238817d-181e-4822-e68f-ab9cc3c103d2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': [SystemMessage(content='Current summary: \\nThe human greeted the AI. The AI responded by asking what was happening. \\n')]}"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["我们也可以直接利用 `predict_new_summary` 方法："],"metadata":{"id":"sqNCMxoA_4Nz"}},{"cell_type":"code","source":["messages = memory.chat_memory.messages\n","messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2JPtwbg_fIo","executionInfo":{"status":"ok","timestamp":1715235360839,"user_tz":-480,"elapsed":365,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"75b8baca-213c-4837-f4f8-ae33365514be"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='hi'), AIMessage(content='whats up')]"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["previous_summary = \"\"\n","memory.predict_new_summary(messages, previous_summary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"LmerR7v7_nia","executionInfo":{"status":"ok","timestamp":1715235375719,"user_tz":-480,"elapsed":1569,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"03f5d55c-15cd-4cee-995d-f82af9366000"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Current summary:\\nThe human greeted the AI. The AI responded by asking what was happening. \\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["#### Initializing with messages/existing summary"],"metadata":{"id":"heusMU1Z_8r4"}},{"cell_type":"markdown","source":["你可以轻松地用 `ChatMessageHistory` 初始化 `ConversationSummaryMemory`。在加载时，会自动生成一个总结。"],"metadata":{"id":"b02A3hiSALqb"}},{"cell_type":"code","source":["history = ChatMessageHistory()\n","history.add_user_message(\"hi\")\n","history.add_ai_message(\"hi there!\")\n","\n","memory = ConversationSummaryMemory.from_messages(\n","    llm=llm,\n","    chat_memory=history,\n","    return_messages=True\n",")\n","\n","memory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aF1lnvtkAJI6","executionInfo":{"status":"ok","timestamp":1715235556707,"user_tz":-480,"elapsed":1365,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"d4df5ba9-94ad-48da-8847-74807a2c3a17"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConversationSummaryMemory(llm=GoogleGenerativeAI(model='gemini-1.5-pro-latest', google_api_key=SecretStr('**********'), client=genai.GenerativeModel(\n","    model_name='models/gemini-1.5-pro-latest',\n","    generation_config={},\n","    safety_settings={},\n","    tools=None,\n","    system_instruction=None,\n",")), chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='hi'), AIMessage(content='hi there!')]), return_messages=True, buffer='Current summary: \\nThe human greeted the AI. The AI returned the greeting. \\n')"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["memory.buffer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9AtBQnsyAW3a","executionInfo":{"status":"ok","timestamp":1715235560389,"user_tz":-480,"elapsed":369,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"d7ea5ae7-704b-4673-90cc-d4ea48c1cc6f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Current summary: \\nThe human greeted the AI. The AI returned the greeting. \\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["你可以使用之前生成的总结来加速初始化，并通过直接初始化来避免重新生成总结。"],"metadata":{"id":"Hw8GM7J7AiwQ"}},{"cell_type":"code","source":["memory = ConversationSummaryMemory(\n","    llm=llm,\n","    buffer=\"The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\",\n","    chat_memory=history,\n","    return_messages=True\n",")\n","memory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWPMe1lAAkKy","executionInfo":{"status":"ok","timestamp":1715235676219,"user_tz":-480,"elapsed":332,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"5874fdaa-d02a-436f-9faf-52c9a356ee0c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConversationSummaryMemory(llm=GoogleGenerativeAI(model='gemini-1.5-pro-latest', google_api_key=SecretStr('**********'), client=genai.GenerativeModel(\n","    model_name='models/gemini-1.5-pro-latest',\n","    generation_config={},\n","    safety_settings={},\n","    tools=None,\n","    system_instruction=None,\n",")), chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='hi'), AIMessage(content='hi there!')]), return_messages=True, buffer='The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.')"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["### Conversation Token Buffer"],"metadata":{"id":"Dbg1HsrnCNn8"}},{"cell_type":"markdown","source":["`ConversationTokenBufferMemory` 在内存中保持了一段最近互动的缓存，并使用 Token 的长度而不是互动的数量来决定何时清除互动。"],"metadata":{"id":"wduwf26oCRq1"}},{"cell_type":"code","source":["from langchain.memory import ConversationTokenBufferMemory\n","\n","memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=10)\n","memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n","memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ijh19eZJCcGu","executionInfo":{"status":"ok","timestamp":1715236130861,"user_tz":-480,"elapsed":1193,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"65c3716e-0307-4729-d823-d139a0268707"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: not much you\\nAI: not much'}"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["### Conversation Summary Buffer"],"metadata":{"id":"2I9cxC7XBFY5"}},{"cell_type":"markdown","source":["`ConversationSummaryBufferMemory` 融合了两种方法。它会在内存中保留最近交互的一个缓存，并不是简单地丢弃旧的交互记录，而是将它们汇总成一份摘要，然后同时使用缓存与摘要。此外，它根据 Token 的使用长度而非交互次数来决定什么时候从缓存中移除旧的交互信息。"],"metadata":{"id":"1KaAuBRABHDb"}},{"cell_type":"code","source":["from langchain.memory import ConversationSummaryBufferMemory\n","\n","memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=10)\n","memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n","memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voVqb05jB8CU","executionInfo":{"status":"ok","timestamp":1715235985881,"user_tz":-480,"elapsed":2571,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"510276cd-4f99-4ee0-ec06-4054a9b24999"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'System: Current summary:\\nThe human greets the AI. The AI responds with an informal greeting. \\n\\nHuman: not much you\\nAI: not much'}"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["## 其它"],"metadata":{"id":"R8THWrNIQuTT"}},{"cell_type":"markdown","source":["### Automatic History Management"],"metadata":{"id":"oTonEv-NArq8"}},{"cell_type":"markdown","source":["在之前的例子中，我们显式地将信息传递给处理流程。这种做法是可以接受的，但它需要额外管理新增的信息。LangChain 还提供了一个名为 `RunnableWithMessageHistory` 的 LCEL 链的包装器，能够自动管理这一流程。\n","\n","为了演示其工作原理，我们对上述代码进行了小幅修改，以便使用最后的 `input` 变量，在聊天记录后填充一个 `HumanMessage` 模板。这意味着我们需要一个名为 `chat_history` 的参数，该参数需要包含当前消息之前的所有消息，而不包括当前消息本身。"],"metadata":{"id":"KNYB9GDkAtuq"}},{"cell_type":"code","source":["chat = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\", google_api_key=API_KEY)\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"chat_history\"),\n","        (\"human\", \"{input}\"),\n","    ]\n",")\n","\n","chain = prompt | chat"],"metadata":{"id":"QEP96BhFBT4W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["我们将在这里向对话传递最新输入，然后让 `RunnableWithMessageHistory` 类封装我们的链，并将 `input` 变量追加到聊天记录中。"],"metadata":{"id":"weZCegZYBg1M"}},{"cell_type":"code","source":["from langchain_core.runnables.history import RunnableWithMessageHistory\n","\n","demo_ephemeral_chat_history_for_chain = ChatMessageHistory()\n","\n","chain_with_message_history = RunnableWithMessageHistory(\n","    chain,\n","    lambda session_id: demo_ephemeral_chat_history_for_chain,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"chat_history\",\n",")"],"metadata":{"id":"ef8x1pHHBkA0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["除了我们要封装的链之外，该类还需要一些参数：\n","\n","- 一个工厂方法，它根据给定的会话 ID 返回相关的消息历史。这使得您的处理流程能够同时为多个用户服务，通过为不同的对话加载对应的消息。\n","- `input_messages_key` 用于指定输入中的哪一部分内容需要被监测并记录在聊天历史里。在这个例子里，我们想要监测并记录作为 `input` 参数传入的那部分字符串。\n","- `history_messages_key` 用于指定先前消息应该如何被插入到提示中。在我们的提示中有一个名为 `chat_history` 的 `MessagesPlaceholder`，因此我们设置此属性以确保名称相对应。\n","- （对于那些生成多个结果的处理流程）一个 `output_messages_key` 设置项用于指定哪部分输出应记录为历史信息。它正好与 `input_messages_key` 相对应。\n","\n","我们可以像平常一样使用这个新链，只需额外指定一个 `configurable` 字段，用以指明会话的特定 `session_id`，并将其传递给工厂方法。在这个演示中，我们并没有使用这个字段，但在真实应用场景中，你可能需要返回一个与传入的会话 ID 相匹配的聊天历史记录。"],"metadata":{"id":"4xtv0SWACLSX"}},{"cell_type":"code","source":["response = chain_with_message_history.invoke(\n","    {\"input\": \"Translate this sentence from English to French: I love programming.\"},\n","    {\"configurable\": {\"session_id\": \"unused\"}},\n",")\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZ8iacCkFK09","executionInfo":{"status":"ok","timestamp":1715220153992,"user_tz":-480,"elapsed":1692,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"91638c08-3210-4de0-c51f-dac4dc955b9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_core.tracers.base:Parent run e861d8ea-893d-47ac-9c11-fb269f60ea12 not found for run e8685ba2-1cf8-47a8-8a46-631d238860f9. Treating as a root run.\n"]},{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"J'adore programmer. \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-80dfa9c4-d6e2-4a61-aa6f-e5442179916c-0')"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["response = chain_with_message_history.invoke(\n","    {\"input\": \"What did I just ask you?\"}, {\"configurable\": {\"session_id\": \"unused\"}}\n",")\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDywTLAiFw02","executionInfo":{"status":"ok","timestamp":1715220199000,"user_tz":-480,"elapsed":1690,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"15f0478c-0f56-4a48-ba57-082fa596469e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_core.tracers.base:Parent run ba974403-4f17-46e0-95dd-e4c1604af872 not found for run 8d8021c4-641a-49eb-80ab-95afca74889f. Treating as a root run.\n"]},{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='You asked me to translate the sentence \"I love programming\" from English to French. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-44501353-255d-4183-abeb-c420cf64b783-0')"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["### Modifying Chat History"],"metadata":{"id":"KmCjy8xpF5WG"}},{"cell_type":"markdown","source":["编辑保存的聊天记录能够使您的聊天机器人适应多种不同的情景。这里有几个例子："],"metadata":{"id":"8Z1UMf2XF7LJ"}},{"cell_type":"markdown","source":["#### Trimming Messages"],"metadata":{"id":"L9vRXAp2GCfc"}},{"cell_type":"markdown","source":["LLMs 和 ChatModels 处理信息时有着数量上的限制。即便您没有触及这些限制，可能仍希望减少模型在解析时需要考虑的无关信息。一种做法是仅保留和处理最近接收到的 `n` 条消息。以下是一个包含若干预存消息的历史记录示例："],"metadata":{"id":"YqhQ1ZMIGFCD"}},{"cell_type":"code","source":["demo_ephemeral_chat_history = ChatMessageHistory()\n","\n","demo_ephemeral_chat_history.add_user_message(\"Hey there! I'm Nemo.\")\n","demo_ephemeral_chat_history.add_ai_message(\"Hello!\")\n","demo_ephemeral_chat_history.add_user_message(\"How are you today?\")\n","demo_ephemeral_chat_history.add_ai_message(\"Fine thanks!\")\n","\n","demo_ephemeral_chat_history.messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uEtpWoUKGhVq","executionInfo":{"status":"ok","timestamp":1715220432807,"user_tz":-480,"elapsed":344,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"234a8b98-999a-48c9-b2d0-dcfed368c614"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content=\"Hey there! I'm Nemo.\"),\n"," AIMessage(content='Hello!'),\n"," HumanMessage(content='How are you today?'),\n"," AIMessage(content='Fine thanks!')]"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["我们将这些历史消息和我们之前定义的 `RunnableWithMessageHistory` 数据处理流程一同使用："],"metadata":{"id":"etqh8T9iG20M"}},{"cell_type":"code","source":["prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"chat_history\"),\n","        (\"human\", \"{input}\"),\n","    ]\n",")\n","\n","chain = prompt | chat\n","\n","chain_with_message_history = RunnableWithMessageHistory(\n","    chain,\n","    lambda session_id: demo_ephemeral_chat_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"chat_history\",\n",")\n","\n","response = chain_with_message_history.invoke(\n","    {\"input\": \"What's my name?\"},\n","    {\"configurable\": {\"session_id\": \"unused\"}},\n",")\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQs23ZsZG3t_","executionInfo":{"status":"ok","timestamp":1715220524500,"user_tz":-480,"elapsed":1230,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"67d8f493-e4a0-4f5c-a90a-77d545228004"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_core.tracers.base:Parent run 0ddaab4b-5ead-4c80-ac16-02e1d8413e5e not found for run 69520eb9-302b-40da-9b3f-4a21984a1f68. Treating as a root run.\n"]},{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='Nemo! \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-5174d81b-e1bd-4cab-8b0e-47f689cb3c91-0')"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["我们可以观察到，处理流程保存了之前预先加载的名字信息。\n","\n","但是如果我们面对的上下文空间非常有限，而我们又想减少传给处理流程的消息数量，保留为最近的两条信息。此时我们可以采用 `clear` 方法删除历史消息并重新将必要的信息加入历史记录。虽然这不是必需的，但为了确保这个方法总能被执行，我们可以将其放置在处理流程的开始位置："],"metadata":{"id":"cYcnHO-HHOvN"}},{"cell_type":"code","source":["from langchain_core.runnables import RunnablePassthrough\n","\n","\n","def trim_messages(chain_input):\n","    stored_messages = demo_ephemeral_chat_history.messages\n","    if len(stored_messages) <= 2:\n","        return False\n","\n","    demo_ephemeral_chat_history.clear()\n","\n","    for message in stored_messages[-2:]:\n","        demo_ephemeral_chat_history.add_message(message)\n","\n","    return True\n","\n","\n","chain_with_trimming = (\n","    RunnablePassthrough.assign(messages_trimmed=trim_messages)\n","    | chain_with_message_history\n",")"],"metadata":{"id":"uXE5JeqtHniG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = chain_with_trimming.invoke(\n","    {\"input\": \"How are you today?\"},\n","    {\"configurable\": {\"session_id\": \"unused\"}},\n",")\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KEcyn46nHzG-","executionInfo":{"status":"ok","timestamp":1715220799080,"user_tz":-480,"elapsed":2190,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"7c83a0bb-6072-428a-f9f9-43adb4dbcaea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_core.tracers.base:Parent run c7764b83-33b6-4e53-8b32-bb35ae0d8e4b not found for run 7b643376-0fca-492d-9bbc-cf3d515ddae9. Treating as a root run.\n"]},{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"I am an AI language model, so I don't have feelings like humans do. However, I'm here to assist you and make your day better in any way I can! How can I help you today? \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-027922c9-4014-4f15-8405-59808e0f2ef9-0')"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["demo_ephemeral_chat_history.messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjkHIU1oIIP4","executionInfo":{"status":"ok","timestamp":1715220810973,"user_tz":-480,"elapsed":341,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"dbb2ca88-494f-434a-8a47-aa9d6d4fbf40"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content=\"What's my name?\"),\n"," AIMessage(content='Nemo! \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-5174d81b-e1bd-4cab-8b0e-47f689cb3c91-0'),\n"," HumanMessage(content='How are you today?'),\n"," AIMessage(content=\"I am an AI language model, so I don't have feelings like humans do. However, I'm here to assist you and make your day better in any way I can! How can I help you today? \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-027922c9-4014-4f15-8405-59808e0f2ef9-0')]"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["通过这种方式，我们可以看到过去最早的两条消息已经从记录中删除，而最新的对话内容被添加到了历史记录的最后部分。当再次运行这个处理流程时，`trim_messages` 方法会被重新执行，且仅有两条最新的消息被传递给模型。在这种情况下，模型将在下一次执行时忘记我们之前给予的名字信息："],"metadata":{"id":"HscHr_vRIYYu"}},{"cell_type":"code","source":["response = chain_with_trimming.invoke(\n","    {\"input\": \"What is my name?\"},\n","    {\"configurable\": {\"session_id\": \"unused\"}},\n",")\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUCC797BIb8g","executionInfo":{"status":"ok","timestamp":1715220910760,"user_tz":-480,"elapsed":1871,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"475ad69d-e388-4230-8e2b-4ea07809b8e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_core.tracers.base:Parent run ade213b7-3b23-44d4-a835-fa5bad6c6615 not found for run 5662b4e8-de3c-4233-9f3e-97f21132ca83. Treating as a root run.\n"]},{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"I don't have access to past conversations, so I don't know your name. Would you like to tell me? \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-3a1e833f-90d3-465d-a295-ba72de0bf773-0')"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["demo_ephemeral_chat_history.messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8cnFOWAIjZw","executionInfo":{"status":"ok","timestamp":1715220922040,"user_tz":-480,"elapsed":319,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"82e41207-6702-4f45-9709-ba58e9ae6616"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='How are you today?'),\n"," AIMessage(content=\"I am an AI language model, so I don't have feelings like humans do. However, I'm here to assist you and make your day better in any way I can! How can I help you today? \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-027922c9-4014-4f15-8405-59808e0f2ef9-0'),\n"," HumanMessage(content='What is my name?'),\n"," AIMessage(content=\"I don't have access to past conversations, so I don't know your name. Would you like to tell me? \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-3a1e833f-90d3-465d-a295-ba72de0bf773-0')]"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["#### Summary Memory"],"metadata":{"id":"GaaSxCj6IlaF"}},{"cell_type":"markdown","source":["我们还可以将这种模式应用于其他场景。比如，我们可以在调用我们的链之前，利用一个额外的大语言模型来自动生成这段对话的概要。下面我们重新构建聊天历史记录和聊天机器人处理流程："],"metadata":{"id":"zbqeuPuhIn2y"}},{"cell_type":"code","source":["demo_ephemeral_chat_history = ChatMessageHistory()\n","\n","demo_ephemeral_chat_history.add_user_message(\"Hey there! I'm Nemo.\")\n","demo_ephemeral_chat_history.add_ai_message(\"Hello!\")\n","demo_ephemeral_chat_history.add_user_message(\"How are you today?\")\n","demo_ephemeral_chat_history.add_ai_message(\"Fine thanks!\")\n","\n","demo_ephemeral_chat_history.messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F24Obg4PJryQ","executionInfo":{"status":"ok","timestamp":1715221279828,"user_tz":-480,"elapsed":366,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"5225ee11-65dd-4354-b426-42cb3b063fed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content=\"Hey there! I'm Nemo.\"),\n"," AIMessage(content='Hello!'),\n"," HumanMessage(content='How are you today?'),\n"," AIMessage(content='Fine thanks!')]"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["我们将稍微修改提示内容，让大语言模型 (LLM) 明白它要处理的是一个精简的概要，而不是详尽的聊天记录："],"metadata":{"id":"KSF9QxYOKFOH"}},{"cell_type":"code","source":["prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a helpful assistant. Answer all questions to the best of your ability. \"\n","            \"The provided chat history includes facts about the user you are speaking with.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"chat_history\"),\n","        (\"user\", \"{input}\"),\n","    ]\n",")\n","\n","chain = prompt | chat\n","\n","chain_with_message_history = RunnableWithMessageHistory(\n","    chain,\n","    lambda session_id: demo_ephemeral_chat_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"chat_history\",\n",")"],"metadata":{"id":"Y2a7_iVGKHCV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["现在，让我们编写一个可以从以往的交互过程中获取关键信息的函数。我们也可以将这个函数添加到链的前端："],"metadata":{"id":"GxJMi_hcKTQa"}},{"cell_type":"code","source":["def summarize_messages(chain_input):\n","    stored_messages = demo_ephemeral_chat_history.messages\n","    if len(stored_messages) == 0:\n","        return False\n","    summarization_prompt = ChatPromptTemplate.from_messages(\n","        [\n","            MessagesPlaceholder(variable_name=\"chat_history\"),\n","            (\n","                \"user\",\n","                \"Distill the above chat messages into a single summary message. Include as many specific details as you can.\",\n","            ),\n","        ]\n","    )\n","    summarization_chain = summarization_prompt | chat\n","\n","    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n","\n","    demo_ephemeral_chat_history.clear()\n","\n","    demo_ephemeral_chat_history.add_message(summary_message)\n","\n","    return True\n","\n","\n","chain_with_summarization = (\n","    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n","    | chain_with_message_history\n",")"],"metadata":{"id":"iy0WCieoKX_7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["让我们看看它是否记住了我们给它的名字："],"metadata":{"id":"qeT4S2OYKnCL"}},{"cell_type":"code","source":["response = chain_with_summarization.invoke(\n","    {\"input\": \"What did I say my name was?\"},\n","    {\"configurable\": {\"session_id\": \"unused\"}},\n",")\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sogSHJZuKndz","executionInfo":{"status":"ok","timestamp":1715221476742,"user_tz":-480,"elapsed":3157,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"cadd1ff6-1f27-4876-a7e4-76f6893c8db0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_core.tracers.base:Parent run 66db5a0e-7b66-4432-9fed-a5b559064f03 not found for run 630e9b5b-4af2-4530-82c8-e2a0e31a8c6b. Treating as a root run.\n"]},{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='You said your name was Nemo. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-bd2c4686-dc8f-47d4-a7a2-cfd19e4cd091-0')"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["demo_ephemeral_chat_history.messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-KAmu-VKtRp","executionInfo":{"status":"ok","timestamp":1715221487182,"user_tz":-480,"elapsed":2,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"f351bf2c-e492-4030-b9f2-129e2dd9685d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[AIMessage(content='Nemo greeted the assistant and asked how they were doing. The assistant replied that they were doing well. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-431872aa-72b5-42b7-9cf5-effd32135343-0'),\n"," HumanMessage(content='What did I say my name was?'),\n"," AIMessage(content='You said your name was Nemo. \\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-bd2c4686-dc8f-47d4-a7a2-cfd19e4cd091-0')]"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["请注意，每当再次运行这个处理流程时，它都会根据现有的摘要及新增的信息生成一个新的摘要。同样，您也可以采取一种折中的方式，在保留聊天历史记录中的一部分消息的同时，将其它部分消息制作成摘要。"],"metadata":{"id":"OH-amO1FK-nd"}}]}