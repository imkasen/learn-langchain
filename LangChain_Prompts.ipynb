{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNRVZC1X0Q/cplhQKKnMWDN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%pip install --upgrade --quiet langchain"],"metadata":{"id":"tsH4YpQxCyka"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prompts"],"metadata":{"id":"oIlOubtPBUy9"}},{"cell_type":"markdown","source":["一个大语言模型的提示是用户提供的一组指令或输入，用来引导模型的响应，帮助它理解上下文和生成相关且连贯的基于语言的输出，例如回答问题、完成句子或参与对话。\n","\n","提示模板是一种预设的格式，用于为语言模型生成引导指令。\n","\n","一个模板可能包含指令、少样本示例以及为特定任务准备的具体上下文和问题。\n","\n","通常情况下，语言模型预期接收的提示是一个字符串，或者是一个聊天信息的列表。"],"metadata":{"id":"1rlxNwsdBWI6"}},{"cell_type":"markdown","source":["## `PromptTemplate`"],"metadata":{"id":"NZznHRhRCXFF"}},{"cell_type":"markdown","source":["`PromptTemplate` 可以用来为字符串提示创建一个模板。默认情况下，`PromptTemplate` 利用 Python 中的 [str.format](https://docs.python.org/3/library/stdtypes.html#str.format) 方法来创建字符串模板。"],"metadata":{"id":"VLHwnJk3ELNg"}},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate\n","\n","prompt_template = PromptTemplate.from_template(\n","    \"Tell me a {adjective} joke about {content}.\"\n",")\n","prompt_template"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qke1_sGlCjh8","executionInfo":{"status":"ok","timestamp":1715060210950,"user_tz":-480,"elapsed":1328,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"0f8059a3-6b45-4579-c0e8-b319cb5c4ede"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['adjective', 'content'], template='Tell me a {adjective} joke about {content}.')"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["prompt_template.format(adjective=\"funny\", content=\"chickens\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Cy8Nch1yD09K","executionInfo":{"status":"ok","timestamp":1715060213183,"user_tz":-480,"elapsed":318,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"cdd324fe-8ae8-453f-b3c3-5421b958a9f9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tell me a funny joke about chickens.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["这个模板可以包含任意多个变量，也可以不包含任何变量："],"metadata":{"id":"iWKQ_gVHEezG"}},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate\n","\n","prompt_template = PromptTemplate.from_template(\"Tell me a joke\")\n","prompt_template"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ava1j-czDQKS","executionInfo":{"status":"ok","timestamp":1715060291938,"user_tz":-480,"elapsed":330,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"0d67db91-ebd4-4598-a416-2655a326bc65"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=[], template='Tell me a joke')"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["prompt_template.format()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ONnFIaDLD5nY","executionInfo":{"status":"ok","timestamp":1715060294949,"user_tz":-480,"elapsed":263,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"a106f2ff-b645-4104-be55-e53bf76f028c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tell me a joke'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["在操作字符串提示时，各个模板将被连续地组合起来，不过列表中的首个元素需要是一个提示。"],"metadata":{"id":"KG08ySYOE33k"}},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate\n","\n","prompt = (\n","    PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n","    + \", make it funny\"\n","    + \"\\n\\nand in {language}\"\n",")\n","prompt"],"metadata":{"id":"vDmH8oaKE6Sw","executionInfo":{"status":"ok","timestamp":1715060303213,"user_tz":-480,"elapsed":263,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"a9bc26fe-835f-44b4-9aa5-1f0c3e37b227","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['language', 'topic'], template='Tell me a joke about {topic}, make it funny\\n\\nand in {language}')"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["prompt.format(topic=\"sports\", language=\"spanish\")"],"metadata":{"id":"daOOWXvzFdFi","executionInfo":{"status":"ok","timestamp":1715060318557,"user_tz":-480,"elapsed":269,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"1f86daed-595f-4423-89ec-deab16e97c52","colab":{"base_uri":"https://localhost:8080/","height":35}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tell me a joke about sports, make it funny\\n\\nand in spanish'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## `ChatPromptTemplate`"],"metadata":{"id":"SVb9iZM6Ehfi"}},{"cell_type":"markdown","source":["ChatModels 的提示是一个包含多条聊天消息的列表。\n","\n","每条聊天消息都关联一段内容，并有一个称作 `role` 的附加参数。\n","\n","像这样创建一个 `ChatPromptTemplate`："],"metadata":{"id":"swjUXQv-kuqD"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","chat_template = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n","        (\"human\", \"Hello, how are you doing?\"),\n","        (\"ai\", \"I'm doing well, thanks!\"),\n","        (\"human\", \"{user_input}\"),\n","    ]\n",")\n","\n","messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n","messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RJn0jVxUk7_K","executionInfo":{"status":"ok","timestamp":1715060639767,"user_tz":-480,"elapsed":3,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"624efb42-76e2-4288-d3af-6d940c6a1b2a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n"," HumanMessage(content='Hello, how are you doing?'),\n"," AIMessage(content=\"I'm doing well, thanks!\"),\n"," HumanMessage(content='What is your name?')]"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["`ChatPromptTemplate.from_messages` 静态方法能够接收多种形式的消息，并为将这些消息准确无误地传递到聊天模型提供了一个便捷的方法。"],"metadata":{"id":"n2WAlwxVl2HJ"}},{"cell_type":"code","source":["from langchain_core.messages import SystemMessage\n","from langchain_core.prompts import HumanMessagePromptTemplate\n","\n","chat_template = ChatPromptTemplate.from_messages(\n","    [\n","        SystemMessage(\n","            content=(\n","                \"You are a helpful assistant that re-writes the user's text to \"\n","                \"sound more upbeat.\"\n","            )\n","        ),\n","        HumanMessagePromptTemplate.from_template(\"{text}\"),\n","    ]\n",")\n","\n","messages = chat_template.format_messages(text=\"I don't like eating tasty things\")\n","print(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78Q75GR6l6Om","executionInfo":{"status":"ok","timestamp":1715060849877,"user_tz":-480,"elapsed":285,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"423c3bba-9441-4f38-ddbb-a72210804062"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"), HumanMessage(content=\"I don't like eating tasty things\")]\n"]}]},{"cell_type":"code","source":["from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n","\n","prompt = SystemMessage(content=\"You are a nice pirate\")\n","new_prompt = (\n","    prompt + HumanMessage(content=\"hi\") + AIMessage(content=\"what?\") + \"{input}\"\n",")\n","messages = new_prompt.format_messages(input=\"i said hi\")\n","messages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c-wKHXfioeOz","executionInfo":{"status":"ok","timestamp":1715061977853,"user_tz":-480,"elapsed":2,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"ccfa8c3e-7348-4167-e0bd-41ecacca201e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[SystemMessage(content='You are a nice pirate'),\n"," HumanMessage(content='hi'),\n"," AIMessage(content='what?'),\n"," HumanMessage(content='i said hi')]"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## Message Prompts"],"metadata":{"id":"EHAqU3EpnVt6"}},{"cell_type":"markdown","source":["LangChain 提供了不同种类的 `MessagePromptTemplate`。\n","\n","其中，最常用的模板包括 `AIMessagePromptTemplate`、`SystemMessagePromptTemplate` 和 `HumanMessagePromptTemplate`，它们分别用于生成 AI 消息、系统消息和面向人类的消息。\n","\n","来比较一下 `PromptTemplate` 和 `Message` 之间的区别："],"metadata":{"id":"r5JkTdcntth2"}},{"cell_type":"code","source":["from langchain_core.prompts import SystemMessagePromptTemplate\n","from langchain_core.messages import SystemMessage\n","\n","smpt = SystemMessagePromptTemplate.from_template(\"You are a helpful assistant, {etc}\")\n","sm = SystemMessage(content=\"You are a nice pirate\")\n","smpt, sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7swhWrguDxI","executionInfo":{"status":"ok","timestamp":1715063615045,"user_tz":-480,"elapsed":329,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"3db550dc-fa5c-4267-94e3-1e8e832e0660"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['etc'], template='You are a helpful assistant, {etc}')),\n"," SystemMessage(content='You are a nice pirate'))"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["from langchain_core.prompts import AIMessagePromptTemplate\n","from langchain_core.messages import AIMessage\n","\n","aimpt = AIMessagePromptTemplate.from_template(\"Nice, {something}\")\n","aim = AIMessage(content=\"Fine\")\n","aimpt, aim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HHIVeYoduj6r","executionInfo":{"status":"ok","timestamp":1715063809828,"user_tz":-480,"elapsed":562,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"f36b7f3b-413c-4a79-c4b1-bbd97df596e0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['something'], template='Nice, {something}')),\n"," AIMessage(content='Fine'))"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["from langchain_core.prompts import HumanMessagePromptTemplate\n","from langchain_core.messages import HumanMessage\n","\n","hmpt = HumanMessagePromptTemplate.from_template(\"Hello\")\n","hm = HumanMessage(content=\"hi\")\n","hmpt, hm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1LKYeTItDm4","executionInfo":{"status":"ok","timestamp":1715062756202,"user_tz":-480,"elapsed":284,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"41befdba-4dc2-48de-b362-83d99a99963f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Hello')),\n"," HumanMessage(content='hi'))"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["区别在于 `PromptTemplate` 可以用来创建字符串模板并插入变量。"],"metadata":{"id":"MS_AzXKmxmtM"}},{"cell_type":"markdown","source":["当聊天模型能够处理带有任意指定角色的消息时，你可以选用 `ChatMessagePromptTemplate`。这种模板使得用户能够自由定义角色名称。"],"metadata":{"id":"IrXjE9YVnY24"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatMessagePromptTemplate\n","\n","prompt = \"May the {subject} be with you\"\n","\n","chat_message_prompt = ChatMessagePromptTemplate.from_template(\n","    role=\"Jedi\", template=prompt\n",")\n","chat_message_prompt.format(subject=\"force\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WvIivqYlqFiT","executionInfo":{"status":"ok","timestamp":1715061940990,"user_tz":-480,"elapsed":304,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"d1eedbd6-483b-4f07-94f1-9b707f8d7bb4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatMessage(content='May the force be with you', role='Jedi')"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## `MessagesPlaceholder`"],"metadata":{"id":"3yYjGF2iqg15"}},{"cell_type":"markdown","source":["LangChain 还提供 `MessagesPlaceholder`，它让你能够精确控制在格式化文本时要展示的信息内容。这在你不确定该为信息模板选择哪种角色，或者想要在文本格式化时加入一串特定信息列表时，尤为有用。"],"metadata":{"id":"pZ7-OPE8qi_f"}},{"cell_type":"code","source":["from langchain_core.prompts import (\n","    ChatPromptTemplate,\n","    HumanMessagePromptTemplate,\n","    MessagesPlaceholder,\n",")\n","\n","human_prompt = \"Summarize our conversation so far in {word_count} words.\"\n","human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n","human_message_template"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZnJQcT3rNSe","executionInfo":{"status":"ok","timestamp":1715062298475,"user_tz":-480,"elapsed":264,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"07436594-2a19-434f-8f8e-26eb2e79d749"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], template='Summarize our conversation so far in {word_count} words.'))"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["chat_prompt = ChatPromptTemplate.from_messages(\n","    [MessagesPlaceholder(variable_name=\"conversation\"), human_message_template]\n",")\n","chat_prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XD5AfcR2rauX","executionInfo":{"status":"ok","timestamp":1715062316190,"user_tz":-480,"elapsed":261,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"10ae3e67-c9a6-457a-aa76-38444d39cf83"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatPromptTemplate(input_variables=['conversation', 'word_count'], input_types={'conversation': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], template='Summarize our conversation so far in {word_count} words.'))])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["from langchain_core.messages import AIMessage, HumanMessage\n","\n","human_message = HumanMessage(content=\"What is the best way to learn programming?\")\n","ai_message = AIMessage(\n","    content=\"\"\"\\\n","1. Choose a programming language: Decide on a programming language that you want to learn.\n","\n","2. Start with the basics: Familiarize yourself with the basic programming concepts such as variables, data types and control structures.\n","\n","3. Practice, practice, practice: The best way to learn programming is through hands-on experience\\\n","\"\"\"\n",")\n","\n","chat_prompt.format_prompt(\n","    conversation=[human_message, ai_message], word_count=\"10\"\n",").to_messages()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SkYGUt1ysFh1","executionInfo":{"status":"ok","timestamp":1715062483056,"user_tz":-480,"elapsed":306,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"5576f38f-dae5-43a6-84e4-5bb9978b7d43"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='What is the best way to learn programming?'),\n"," AIMessage(content='1. Choose a programming language: Decide on a programming language that you want to learn.\\n\\n2. Start with the basics: Familiarize yourself with the basic programming concepts such as variables, data types and control structures.\\n\\n3. Practice, practice, practice: The best way to learn programming is through hands-on experience'),\n"," HumanMessage(content='Summarize our conversation so far in 10 words.')]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## LCEL"],"metadata":{"id":"vldnLsLeyr9c"}},{"cell_type":"markdown","source":["`PromptTemplate` 和 `ChatPromptTemplate` 实现了 Runnable 接口，Runnable 接口是 LangChain 表达式语言（LCEL）的核心组成部分。这意味着它们支持 `invoke`、`ainvoke`、`stream`、`astream`、`batch`、`abatch` 及 `astream_log` 等技术操作的调用。\n","\n","`PromptTemplate` 可以接收一个字典（字典中包含了 prompt 所需的各种变量）并返回一个 `StringPromptValue` 对象。而 `ChatPromptTemplate` 则是接收一个字典并返回一个 `ChatPromptValue` 对象。"],"metadata":{"id":"H91Mz3Qoyusx"}},{"cell_type":"code","source":["prompt_template = PromptTemplate.from_template(\n","    \"Tell me a {adjective} joke about {content}.\"\n",")\n","\n","prompt_val = prompt_template.invoke({\"adjective\": \"funny\", \"content\": \"chickens\"})\n","prompt_val"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-r8hrtbhznWJ","executionInfo":{"status":"ok","timestamp":1715064444942,"user_tz":-480,"elapsed":335,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"eb542f23-cf1e-4665-f546-cb54bb157f17"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StringPromptValue(text='Tell me a funny joke about chickens.')"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["prompt_val.to_string()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"TV3FPEhrzw4L","executionInfo":{"status":"ok","timestamp":1715064477154,"user_tz":-480,"elapsed":303,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"401089c0-be27-4fc4-c5e2-d298cbd57995"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tell me a funny joke about chickens.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["prompt_val.to_messages()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVex6gWGzykE","executionInfo":{"status":"ok","timestamp":1715064484172,"user_tz":-480,"elapsed":371,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"02dfbf62-1062-4416-bfe0-5c47475a19ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[HumanMessage(content='Tell me a funny joke about chickens.')]"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["chat_template = ChatPromptTemplate.from_messages(\n","    [\n","        SystemMessage(\n","            content=(\n","                \"You are a helpful assistant that re-writes the user's text to \"\n","                \"sound more upbeat.\"\n","            )\n","        ),\n","        HumanMessagePromptTemplate.from_template(\"{text}\"),\n","    ]\n",")\n","\n","chat_val = chat_template.invoke({\"text\": \"i dont like eating tasty things.\"})"],"metadata":{"id":"EBoM-DMjz4LV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chat_val.to_messages()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZ5GGWtF0BpW","executionInfo":{"status":"ok","timestamp":1715064545898,"user_tz":-480,"elapsed":341,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"2e4287af-350c-4c73-d37f-352906996f69"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"),\n"," HumanMessage(content='i dont like eating tasty things.')]"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["chat_val.to_string()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"jL5YiYwo0DDw","executionInfo":{"status":"ok","timestamp":1715064551593,"user_tz":-480,"elapsed":3,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"cc31dceb-1a0d-422e-e028-ddd4e2ae4f9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"System: You are a helpful assistant that re-writes the user's text to sound more upbeat.\\nHuman: i dont like eating tasty things.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["## PipelinePrompt"],"metadata":{"id":"3sPGXVSJ3mki"}},{"cell_type":"markdown","source":["当你希望重复使用部分提示时，`PipelinePromptTemplate` 非常有用。一个 PipelinePrompt 主要包含两个部分：\n","\n","- 最终提示：返回的最终提示\n","- 管道提示：一个由元组组成的列表，每个元组包含一个字符串名称和一个提示模板。每个提示模板都将被格式化，然后作为具有相同名称的变量传递给未来的提示模板。"],"metadata":{"id":"fQKv4TZC3o50"}},{"cell_type":"code","source":["from langchain_core.prompts.pipeline import PipelinePromptTemplate\n","from langchain_core.prompts.prompt import PromptTemplate\n","\n","full_template = \"\"\"{introduction}\n","\n","{example}\n","\n","{start}\"\"\"\n","full_prompt = PromptTemplate.from_template(full_template)\n","\n","introduction_template = \"\"\"You are impersonating {person}.\"\"\"\n","introduction_prompt = PromptTemplate.from_template(introduction_template)\n","\n","example_template = \"\"\"Here's an example of an interaction:\n","\n","Q: {example_q}\n","A: {example_a}\"\"\"\n","example_prompt = PromptTemplate.from_template(example_template)\n","\n","start_template = \"\"\"Now, do this for real!\n","\n","Q: {input}\n","A:\"\"\"\n","start_prompt = PromptTemplate.from_template(start_template)\n","\n","input_prompts = [\n","    (\"introduction\", introduction_prompt),\n","    (\"example\", example_prompt),\n","    (\"start\", start_prompt),\n","]\n","pipeline_prompt = PipelinePromptTemplate(\n","    final_prompt=full_prompt, pipeline_prompts=input_prompts\n",")"],"metadata":{"id":"HsGDsk0o4SZ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipeline_prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4iY5jvS41Sa","executionInfo":{"status":"ok","timestamp":1715065811215,"user_tz":-480,"elapsed":325,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"635d4a92-216a-47bb-9844-7aee9646bb25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PipelinePromptTemplate(input_variables=['person', 'example_a', 'example_q', 'input'], final_prompt=PromptTemplate(input_variables=['example', 'introduction', 'start'], template='{introduction}\\n\\n{example}\\n\\n{start}'), pipeline_prompts=[('introduction', PromptTemplate(input_variables=['person'], template='You are impersonating {person}.')), ('example', PromptTemplate(input_variables=['example_a', 'example_q'], template=\"Here's an example of an interaction:\\n\\nQ: {example_q}\\nA: {example_a}\")), ('start', PromptTemplate(input_variables=['input'], template='Now, do this for real!\\n\\nQ: {input}\\nA:'))])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["pipeline_prompt.input_variables"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GsI8TN943hA","executionInfo":{"status":"ok","timestamp":1715065815738,"user_tz":-480,"elapsed":473,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"61ccd993-a529-491c-f87f-718954143084"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['person', 'example_a', 'example_q', 'input']"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["print(\n","    pipeline_prompt.format(\n","        person=\"Elon Musk\",\n","        example_q=\"What's your favorite car?\",\n","        example_a=\"Tesla\",\n","        input=\"What's your favorite social media site?\",\n","    )\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGKzfXDW5DRP","executionInfo":{"status":"ok","timestamp":1715065863617,"user_tz":-480,"elapsed":285,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"1238d07b-e8f0-47cc-eef3-184215c48aa0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["You are impersonating Elon Musk.\n","\n","Here's an example of an interaction:\n","\n","Q: What's your favorite car?\n","A: Tesla\n","\n","Now, do this for real!\n","\n","Q: What's your favorite social media site?\n","A:\n"]}]},{"cell_type":"markdown","source":["## Partial prompt templates"],"metadata":{"id":"mXeatoql6BIM"}},{"cell_type":"markdown","source":["就像其他方法一样，对一个提示模版进行“部分填充”也是有意义的。\n","\n","LangChain 用两种方式支持这个功能：\n","\n","1. 使用字符串值进行部分格式化。\n","2. 使用返回字符串值的函数进行部分格式化。\n","\n","这两种不同的方式支持不同的使用场景。在下面的范例中，我们将分别阐述这两种使用场景的目的，以及如何在 LangChain 中应用。"],"metadata":{"id":"Ppwf17JK6Db2"}},{"cell_type":"markdown","source":["### Partial with strings"],"metadata":{"id":"c2oi8s0H6h30"}},{"cell_type":"markdown","source":["当你需要分批获得不同的变量时，部分填充提示模板就显得非常实用。举个例子，假如你有一个提示模板，里面需要填入两个变量，分别是 `foo` 和 `baz`。如果在处理流程的前期就得到了 `foo` 的值，但是要到后期才能得到 `baz` 的值，整个流程会因为需要同时拥有这两个变量才能继续而变得不那么顺畅。你可以选择先将 `foo` 值填入模板，然后再将这个已填充了 `foo` 值的提示模板传递下去，这样在接下来的步骤中只需要关注 `baz` 值即可。以下是如何做到这一点的示例："],"metadata":{"id":"jPt41PI46jmj"}},{"cell_type":"code","source":["from langchain_core.prompts import PromptTemplate\n","\n","prompt = PromptTemplate.from_template(\"{foo}{bar}\")\n","partial_prompt = prompt.partial(foo=\"foo\")\n","partial_prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3i-YhcLH7RLn","executionInfo":{"status":"ok","timestamp":1715066456422,"user_tz":-480,"elapsed":431,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"7b68914a-96fb-406b-bdca-ecbaf652458a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['bar'], partial_variables={'foo': 'foo'}, template='{foo}{bar}')"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["print(partial_prompt.format(bar=\"baz\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V47Lw85U7SxI","executionInfo":{"status":"ok","timestamp":1715066467425,"user_tz":-480,"elapsed":304,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"4dfd22eb-9b8f-491c-bad9-3c74413d2b70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["foobaz\n"]}]},{"cell_type":"markdown","source":["也可以这么写："],"metadata":{"id":"l4ycaRVOiigx"}},{"cell_type":"code","source":["prompt = PromptTemplate(\n","    template=\"{foo}{bar}\", input_variables=[\"bar\"], partial_variables={\"foo\": \"foo\"}\n",")\n","print(prompt.format(bar=\"baz\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHcGM5pX7ZDz","executionInfo":{"status":"ok","timestamp":1715066485146,"user_tz":-480,"elapsed":305,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"d3d222e0-6774-4d0e-ce76-dca0ac52d5f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["foobaz\n"]}]},{"cell_type":"markdown","source":["### Partial with functions"],"metadata":{"id":"4sTwkfV87ddn"}},{"cell_type":"markdown","source":["另一个方便的应用是利用函数进行部分填充。这个方法特别有助于处理那些你希望以固定模式获取的变量。举个例子，你可能会有一个提示模板，希望它总能自动包含当前的日期或时间。显然，你不可能将一个固定日期写死在模板里，每次还要和其他变量一起手动传入日期也显得比较麻烦。在这种场景下，如果你能够部分填充一个始终能返回当前日期的函数到提示模板中，那将大大简化整个流程。"],"metadata":{"id":"CJYjLWdC7fkN"}},{"cell_type":"code","source":["from datetime import datetime\n","\n","\n","def _get_datetime():\n","    now = datetime.now()\n","    return now.strftime(\"%m/%d/%Y, %H:%M:%S\")"],"metadata":{"id":"A687LeTm77h6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = PromptTemplate(\n","    template=\"Tell me a {adjective} joke about the day {date}\",\n","    input_variables=[\"adjective\", \"date\"],\n",")\n","partial_prompt = prompt.partial(date=_get_datetime)\n","partial_prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHOWZ_u57879","executionInfo":{"status":"ok","timestamp":1715066649406,"user_tz":-480,"elapsed":3,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"298c8093-0ed4-4461-d7db-34aca904d382"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PromptTemplate(input_variables=['adjective'], partial_variables={'date': <function _get_datetime at 0x7ac5c5b988b0>}, template='Tell me a {adjective} joke about the day {date}')"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["print(partial_prompt.format(adjective=\"funny\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5C8IKkr8B_k","executionInfo":{"status":"ok","timestamp":1715066651944,"user_tz":-480,"elapsed":405,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"cde7f421-57ac-4dc6-f8fb-5cb6c79357de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tell me a funny joke about the day 05/07/2024, 07:24:11\n"]}]},{"cell_type":"markdown","source":["也可以这么写："],"metadata":{"id":"ucKmR2c5ivnI"}},{"cell_type":"code","source":["prompt = PromptTemplate(\n","    template=\"Tell me a {adjective} joke about the day {date}\",\n","    input_variables=[\"adjective\"],\n","    partial_variables={\"date\": _get_datetime},\n",")\n","print(prompt.format(adjective=\"funny\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gTP_2phj8Iqr","executionInfo":{"status":"ok","timestamp":1715066671603,"user_tz":-480,"elapsed":2,"user":{"displayName":"Kearl Cordle","userId":"12869362405359631290"}},"outputId":"b2ef5171-2a0c-4afc-aea7-01011f36c7a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tell me a funny joke about the day 05/07/2024, 07:24:31\n"]}]}]}